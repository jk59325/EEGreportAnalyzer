{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "from __future__ import print_function, division, absolute_import\n",
    "\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import csvkit as csv\n",
    "\n",
    "allReports = \"\"\n",
    "with open(\"lpch_eeg_reports_interp_impression.csv\") as cf:\n",
    "    reader = csv.DictReader(cf)\n",
    "    for line in reader:\n",
    "        allReports += line['note'] + \" \\n\\n\"\n",
    "        # print(desc)\n",
    "        # now manipulate the note body\n",
    "        \n",
    "f = open(\"allReports.txt\", \"w\")\n",
    "f.write(allReports)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "words = allReports.split()\n",
    "letter_counts = Counter(words)\n",
    "df = pandas.DataFrame.from_dict(letter_counts, orient='index')\n",
    "df = df.sort_values(by=0, ascending=0)\n",
    "df1 = df[:20]\n",
    "plt.show(block=True)\n",
    "df1.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "report = allReports.lower()\n",
    "reportNLTK = nltk.Text(nltk.tokenize.word_tokenize(report))\n",
    "reportNLTK.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate some eeg reports for me\n",
    "def generate_model(cfdist, word, num=15):\n",
    "    for i in range(num):\n",
    "        print(word, end=' ')\n",
    "        word = cfdist[word].max()\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#text = nltk.corpus.genesis.words('english-kjv.txt')\n",
    "#print(type(text))\n",
    "corpus = nltk.corpus.reader.plaintext.PlaintextCorpusReader(\".\", \"allReports.txt\")\n",
    "words=corpus.words()\n",
    "#get rid of stop words\n",
    "filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
    "words = filtered_words\n",
    "\n",
    "#print(type(words))\n",
    "bigrams = nltk.bigrams(words)\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)\n",
    "generate_model(cfd, 'seizure')\n",
    "#filtered_words = [word for word in word_list if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_model(cfd, 'epileptic')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'slow')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'discharge')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'periodic')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'impression')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'background')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'infantile')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'neonatal')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'seizure')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'seizures')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'This')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'electrographic')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'indicates')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'represent')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'generalized')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'slowing')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'focal')\n",
    "print(\"\")\n",
    "generate_model(cfd, '3')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'hz')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'second')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'button')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'cry')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'clonic')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'tonic')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'partial')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'sleep')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'vertex')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'temporal')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'frontal')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'occipital')\n",
    "print(\"\")\n",
    "generate_model(cfd, 'hypsarrythmia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fraction of words in text that are not in the stopword list\n",
    "def content_fraction(text):\n",
    "     stopwords = nltk.corpus.stopwords.words('english')\n",
    "     content = [w for w in text if w.lower() not in stopwords]\n",
    "     return len(content) / len(text)\n",
    "\n",
    "content_fraction(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in order to load a corpus, reports must be in separate files\n",
    "\n",
    "capture_eegno = r'(?:DATE OF SERVICE:|STUDY DATE:|DATE EEG:|Date:|Service Date:|Study date|Study dates|DATE OF EEG:|start|T:|test dates:|Date of study:|Exam date|exam date:)\\s*(?P<eegno>[\\d/-]+)\\s*'\n",
    "capture_eegno1 = r'(?:Date:|Study date |Study date:)\\s*(?P<eegno>(?:Jan|Feb|Mar|Apr|May|Jun|July|Aug|Sep|Oct|Nov|Dec)\\s*[,\\s\\d/-]+)(?:[a-z]+)'\n",
    "capture_eegno2 = r'(?<!DOB:  )(?P<eegno>[\\d]+/[\\d]+/[\\d]+)' #DOB:  10/04/1993   \n",
    "eegDateRange = r'(?P<eegno>[\\d/]+-[\\d/]+)'\n",
    "eegDateStrict = r'(?P<eegno>[\\d]+/[\\d]+/[\\d]+)'\n",
    "#capture_eegno = r'(?P<eegno>[0-9]+)\\s*'\n",
    "re_eegno = re.compile(capture_eegno, re.DOTALL|re.MULTILINE|re.IGNORECASE)\n",
    "re_eegno1 = re.compile(capture_eegno1, re.DOTALL|re.MULTILINE|re.IGNORECASE)\n",
    "re_eegno2 = re.compile(capture_eegno2, re.DOTALL|re.MULTILINE|re.IGNORECASE)\n",
    "eegDateRange = re.compile(eegDateRange, re.DOTALL|re.MULTILINE|re.IGNORECASE)\n",
    "eegDateStrict = re.compile(eegDateStrict, re.DOTALL|re.MULTILINE|re.IGNORECASE)\n",
    "\n",
    "out_file = open(\"lpch_eeg_reports_interp_date_impression.csv\",'w')\n",
    "\n",
    "i=2\n",
    "with open(\"lpch_eeg_reports_interp_impression.csv\") as cf:\n",
    "    reader = csv.DictReader(cf)\n",
    "    outfieldnames = reader.fieldnames\n",
    "    outfieldnames.append('date')\n",
    "    writer = csv.DictWriter(out_file, fieldnames=outfieldnames, restval='***')\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for line in reader:\n",
    "        eeg_no=\"\"\n",
    "        m = re_eegno.search(line['note'])\n",
    "        print(str(i) + \": \", end='')\n",
    "        #print(str(i) + \": \" + str(type(m)), end='')\n",
    "        if m:\n",
    "            eeg_no = m.group('eegno')\n",
    "            #print(eeg_no)\n",
    "        else:\n",
    "            m = re_eegno1.search(line['note'])\n",
    "            if m:\n",
    "                eeg_no = m.group('eegno')\n",
    "                #print(eeg_no)\n",
    "            else:\n",
    "                #print(\"!!!!!!!!!!!\")\n",
    "                for match in re.finditer(capture_eegno2,line['note']):\n",
    "                    eeg_no = match.group('eegno')\n",
    "                    \n",
    "                #m = re_eegno2.search(line['note'])\n",
    "                #if m:\n",
    "                #    eeg_no = m.group('eegno')\n",
    "                #print(eeg_no +\"???????\")\n",
    "\n",
    "        #if len(eeg_no) > 12:\n",
    "        #    m = eegDateRange.search(eeg_no)            \n",
    "        #    if m:\n",
    "        #        print(\"bad\")\n",
    "        #        m = eegDateStrict.search(eeg_no)\n",
    "        #        m = eegDateStrict.search(eeg_no)\n",
    "        #        if m:\n",
    "        #            eeg_no = m.group('eegno')\n",
    "        if ((len(eeg_no) < 5) | (len(eeg_no) > 12)):\n",
    "            #print(\"possibly bad: \" + eeg_no)\n",
    "            for match in re.finditer(capture_eegno2,line['note']):\n",
    "                eeg_no = match.group('eegno')\n",
    "        line['date'] = eeg_no \n",
    "        writer.writerow(line)\n",
    "        \n",
    "        #print(eeg_no)    \n",
    "        #i += 1\n",
    "        #if (i>600):\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in order to load a corpus, reports must be in separate files\n",
    "from dateutil import parser\n",
    "\n",
    "i=2\n",
    "with open(\"lpch_eeg_reports_interp_date_impression.csv\") as cf:\n",
    "    reader = csv.DictReader(cf)\n",
    "    \n",
    "    for line in reader:\n",
    "        date_str= line['date']\n",
    "        try:\n",
    "            dateObj = parser.parse(date_str)\n",
    "            #print(dateObj.date())\n",
    "            dateFile = (str(dateObj.date()))\n",
    "            f = open(\"reports/\" + dateFile + \".txt\", \"a+\")\n",
    "            f.write(line['note'])\n",
    "            f.close()\n",
    "        except:\n",
    "            print(\"Unexpected error:\", str(sys.exc_info()[0]) + date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "#fileids = os.listdir(\"reports\")\n",
    "corpus_root = 'reports'\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*')\n",
    "wordlists.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (target, fileid[:10])\n",
    "           for fileid in wordlists.fileids()\n",
    "           for w in wordlists.words(fileid)\n",
    "           for target in ['grda', 'gpd']\n",
    "           if w.lower().startswith(target))\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfd.tabulate(conditions=['grda','gpd'], samples=range(10), cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}